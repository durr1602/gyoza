# Technical configuration file for gy≈çza

executor: cluster-generic
cluster-generic-submit-cmd:
  sbatch
    --partition={resources.partition}
    --mem={resources.mem_gb}G
    --cpus-per-task={resources.threads}
    --time={resources.time}
    --job-name=smk-{rule}-{wildcards}
    --output=logs/SLURM_out/{rule}/{rule}-%j-{wildcards}.out
    --mail-type=FAIL
    --mail-user={resources.mail}
    --parsable

default-resources:
  - mail="<YOUR-EMAIL-ADRESS>"
  - partition="small"
  - mem_gb=1
  - threads=10
  - time="00:30:00"

# Dynamic allocation of rule-specific resources
# The following was optimized from internal benchmarking
# Resources allocated should prevent overallocation but might not be enough at first attempt
set-resources:
  fastqc:
    threads: 10
    time: max((0.002 * input.size_mb + (attempt - 1) * 0.002 * input.size_mb).__ceil__(), 1)
  generate_mutants:
    mem_gb: max(50 * input.size_mb + (attempt - 1) * 50 * input.size_mb, 2)
    threads: 1
    time: max((80 * input.size_mb + (attempt - 1) * 80 * input.size_mb).__ceil__(), 1)
  cutadapt:
    threads: 10
    time: max((0.005 * input.size_mb + (attempt - 1) * 0.005 * input.size_mb).__ceil__(), 1)
  pandaseq:
    threads: 4
    time: max((0.002 * input.size_mb + (attempt - 1) * 0.002 * input.size_mb).__ceil__(), 1)
  vsearch_fastx_uniques:
    threads: 1  # This command of vsearch is not multi-threaded
    time: max((0.0002 * input.size_mb + (attempt - 1) * 0.0002 * input.size_mb).__ceil__(), 1)
  stats:
    threads: 1
    time: max((0.001 * input.size_mb + (attempt - 1) * 0.001 * input.size_mb).__ceil__(), 1)
  parse_fasta:
    mem_gb: max((0.002 * input.size_mb + (attempt - 1) * 0.002 * input.size_mb).__ceil__(), 1)
    threads: 1
    time: max((0.002 * input.size_mb + (attempt - 1) * 0.002 * input.size_mb).__ceil__(), 1)
  process_read_counts:
    mem_gb: max((0.2 * input.size_mb + (attempt - 1) * 0.2 * input.size_mb).__ceil__(), 1)
    threads: 1
    time: max((0.5 * input.size_mb + (attempt - 1) * 0.5 * input.size_mb).__ceil__(), 1)

jobs: 500
max-jobs-per-second: 10
max-status-checks-per-second: 1
local-cores: 1
latency-wait: 60
keep-going: True
rerun-incomplete: True
restart-times: 3
printshellcmds: True
scheduler: greedy
use-conda: True
cluster-generic-cancel-cmd: scancel
cluster-generic-cancel-nargs: 1000
cluster-generic-status-cmd: status-sacct.sh
